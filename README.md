# Analysis-of-Road-Accidents-in-UK

# Project at a Glance:

# Language Used
Python

# Libraries Used
1. Pandas
2. Matplotlib
3. Numpy
4. Seaborn
5. Pywaffle
6. Plotly.express

# Number of Plots
20


# OBJECTIVE
All of us very well know that the road traffic accidents have emerged as a major public health hazard with a number of RTA’s taking place every year and so it is our responsibility to derive a suitable relationship between the accidents and the external factors that cause them so we can reduce the number of RTA’s and loss of life in the long run. Few factors that cause RTAs include the road and climate conditions, over speeding, distracted driving and jumping the red signal. So, the main objective of this project is to analyse the various road traffic accidents that had taken place in the United Kingdom from the year 2005 to 2014 from the dataset. In this project we will deploy various data visualization techniques and methodologies to find the pattern and insights from the dataset used. Several modelling techniques are used for data analysis in doing so to find out how to drive safely. From this project we will also know the parameters that cause traffic accidents. We can also get a lot of driving suggestions as well and control them in the long run.

# PROPOSED METHODOLOGY
The designed proposed methodology is intended to be portable to any visualization challenge; it presents a sequence of important analytical and design tasks and decisions that need to be handled effectively. Visualizing data is a complex process that contains complex problems and efficient methods of interpretation with greater efficiency, effectiveness and elegance. Adopting this methodology is about recognizing the key stages, considerations, and tactics that will help you navigate smoothly through the visualization project
In data analysis the analysis is 100% rigid is a bold statement to make rather a linear process and indeed some of the stages may occasionally switch in sequence and require iteration. That is new factors and branches to data can emerge at any stage and may affect the visualization strategy and solutions to it. so, it is important to keep the visualization technique flexible at all levels.

In data visualization one can rarely, if ever, say that a problem can have a single answer or a single best possible answer. It is much more about heuristic methods to determine the most satisfactory solutions.


# INTERPRETING FLOWCHART:
The Visual Analytics Process combines automatic and visual analysis methods with a tight coupling through human interaction in order to gain knowledge from data. The figure shows an abstract overview of the flow in between different stages and transitions in the data visualization process. The first step is often to pre-process and transform the data to derive different representations for further exploration. Other typical pre-processing tasks include data cleaning, normalization, grouping, or integration of heterogeneous data sources. After the transformation, the analyst may choose between applying visual or automatic analysis methods.
If an automated analysis is used first; data mining methods are applied to generate models of the original data. Once the pre model is declared and created it is important to evaluate and refine models which best done by interacting with the data with the questions what (what data the user see?), why (why user intent to use visualization tools?), how (how visual encoding and interaction idioms are constructed?). In brief we can conclude that Visual Analytics Process knowledge can be gained from visualization, automatic analysis, as well as the preceding interactions between visualizations, models, and the human analysts. Hence proposed methodology is an important technique for clear data visualization and on point analysis of the data with better understanding and efficient knowledge gained in a time bound manner. Else there is infinite data and infinite ways to interpret it but very few methods are there which efficiently channelize the purpose of studying the particular data in a precise manner.
